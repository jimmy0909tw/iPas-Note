<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI 應用規劃師 (初級) 考試(科目一)筆記 </title>
    <style>
        body {
            font-family: 'Microsoft JhengHei', 'Segoe UI', Arial, sans-serif;
            line-height: 1.6;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f8f9fa;
            color: #333;
        }
        
        .container {
            background-color: white;
            border-radius: 12px;
            box-shadow: 0 4px 12px rgba(0,0,0,0.1);
            padding: 30px;
        }
        
        h1 {
            color: #2c3e50;
            font-size: 28px;
            font-weight: 700;
            text-align: center;
            margin-bottom: 30px;
            padding-bottom: 15px;
            border-bottom: 3px solid #3498db;
        }
        
        h2 {
            color: #e74c3c;
            font-size: 24px;
            font-weight: 600;
            margin-top: 35px;
            margin-bottom: 20px;
            padding: 10px;
            background: linear-gradient(135deg, #ffe6e6, #fff);
            border-left: 5px solid #e74c3c;
            border-radius: 5px;
        }
        
        h3 {
            color: #8e44ad;
            font-size: 20px;
            font-weight: 600;
            margin-top: 25px;
            margin-bottom: 15px;
            padding: 8px;
            background: linear-gradient(135deg, #f3e5f5, #fff);
            border-left: 4px solid #8e44ad;
            border-radius: 5px;
        }
        
        h4 {
            color: #2980b9;
            font-size: 18px;
            font-weight: 600;
            margin-top: 20px;
            margin-bottom: 12px;
            padding: 6px;
            background: linear-gradient(135deg, #e3f2fd, #fff);
            border-left: 3px solid #2980b9;
            border-radius: 3px;
        }
        
        h5 {
            color: #d35400;
            font-size: 16px;
            font-weight: 600;
            margin-top: 15px;
            margin-bottom: 10px;
        }
        
        .definition {
            background: linear-gradient(135deg, #e8f4f8, #f8fbff);
            border: 2px solid #17a2b8;
            padding: 15px;
            margin: 15px 0;
            border-radius: 8px;
            box-shadow: 0 2px 6px rgba(23, 162, 184, 0.1);
        }
        
        .key-concept {
            background: linear-gradient(135deg, #fff8e1, #fffef7);
            border: 2px solid #ff9800;
            padding: 15px;
            margin: 15px 0;
            border-radius: 8px;
            box-shadow: 0 2px 6px rgba(255, 152, 0, 0.1);
        }
        
        .example {
            background: linear-gradient(135deg, #e8f5e8, #f1f8e9);
            border: 2px solid #4caf50;
            padding: 15px;
            margin: 15px 0;
            border-radius: 8px;
            box-shadow: 0 2px 6px rgba(76, 175, 80, 0.1);
        }
        
        .comparison {
            background: linear-gradient(135deg, #f0f8ff, #f8fbff);
            border: 2px solid #2196f3;
            padding: 15px;
            margin: 15px 0;
            border-radius: 8px;
            box-shadow: 0 2px 6px rgba(33, 150, 243, 0.1);
        }
        
        .error-analysis {
            background: linear-gradient(135deg, #ffebee, #fff5f5);
            border: 2px solid #f44336;
            padding: 15px;
            margin: 15px 0;
            border-radius: 8px;
            box-shadow: 0 2px 6px rgba(244, 67, 54, 0.1);
        }
        
        .highlight {
            background-color: #ffeb3b;
            padding: 2px 6px;
            border-radius: 4px;
            font-weight: 700;
            color: #333;
        }
        
        .important {
            color: #d32f2f;
            font-weight: 700;
        }
        
        .concept {
            color: #1976d2;
            font-weight: 600;
        }
        
        .technical-term {
            color: #7b1fa2;
            font-weight: 600;
        }
        
        .application {
            color: #388e3c;
            font-weight: 500;
            font-style: italic;
        }
        
        .analogy {
            color: #795548;
            font-style: italic;
            font-weight: 500;
        }
        
        ul, ol {
            margin: 10px 0;
            padding-left: 25px;
        }
        
        li {
            margin: 8px 0;
            line-height: 1.5;
        }
        
        strong {
            font-weight: 700;
        }
        
        .section-divider {
            height: 3px;
            background: linear-gradient(to right, #3498db, #e74c3c, #9c27b0);
            margin: 30px 0;
            border-radius: 2px;
        }
        
        .formula-box {
            background: #f5f5f5;
            border: 1px solid #ddd;
            padding: 10px;
            margin: 10px 0;
            border-radius: 5px;
            font-family: 'Courier New', monospace;
            text-align: center;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>AI 應用規劃師 (初級) 考試筆記 0808版</h1>

        <h2>科目一：人工智慧核心知識與技術</h2>
        
        <h3>第一章：人工智慧概述與基礎概念</h3>
        
        <h4><span class="concept">人工智慧 (AI) 的定義與核心價值</span></h4>
        
        <div class="definition">
            <strong class="technical-term">定義</strong>：AI 是一個廣泛的領域，致力於創造能夠模擬人類智慧行為的機器科學，使其具備學習、推理、感知、理解語言和解決問題的能力。它包含多種技術，例如機器學習、專家系統等。AI 系統的核心能力是從大量數據中自動學習和歸納模式，而非僅僅執行人類明確編寫的複雜數學計算或固定規則。
        </div>
        
        <div class="key-concept">
            <strong class="important">AI 應用的原因與效益</strong>：引入人工智慧的主要原因在於提升效率、增強決策能力及提供個人化服務。對企業而言，導入 AI 技術最直接的影響是<span class="highlight">提升生產力和效率</span>。
            <ul>
                <li><span class="important">提升效率</span>：減少重複性任務的人工操作，例如自動化生產線或數據處理。</li>
                <li><span class="important">增強決策能力</span>：透過分析大量數據，幫助企業做出更精準的商業決策，例如市場趨勢預測。</li>
                <li><span class="important">提供個人化服務</span>：根據用戶偏好提供客製化內容或推薦，提升用戶體驗，例如電商推薦系統。</li>
            </ul>
        </div>

        <h4><span class="concept">AI 的分類</span></h4>
        
        <div class="comparison">
            <h5><span class="technical-term">弱AI (Weak AI) / 狹義AI (Narrow AI)</span>：</h5>
            <ul>
                <li><strong>定義</strong>：僅能在<span class="highlight">特定領域或任務中展現智慧</span>，不具備全面性的人類智慧與意識。這是目前絕大多數 AI 應用的類型。</li>
                <li><strong class="analogy">白話比喻</strong>：想像這就像一個「特定領域的專家」，他可能在下棋（如 Deep Blue）、語音識別（如 Siri）或推薦系統（如 Netflix 的影片推薦）方面非常厲害，但他無法做其他領域的事情，比如幫你煮飯或寫詩。</li>
                <li><span class="application">實際案例</span>：iPhone 的 Siri、醫院用於判讀 X 光片的影像分析軟體、Netflix 的影片推薦系統、特斯拉的自動輔助駕駛。</li>
            </ul>
        </div>
        
        <div class="comparison">
            <h5><span class="technical-term">強AI (Strong AI) / 通用AI (General AI)</span>：</h5>
            <ul>
                <li><strong>定義</strong>：指具備<span class="highlight">人類般的全面智慧、意識和自我學習能力</span>，能夠像人類一樣應對各種前所未見的複雜任務。這是 AI 領域的終極目標。</li>
                <li><strong>延伸知識</strong>：目前強 AI 仍是科幻與學術探討中的理論概念，尚未實現。它的實現將涉及認知科學、哲學等多個領域的重大突破。</li>
                <li><strong class="analogy">白話比喻</strong>：想像這就像科幻電影裡那種無所不能、能思考、有情感的機器人，它不僅能下棋，還能學習新的語言、理解人類的情緒，甚至創造藝術作品。</li>
            </ul>
        </div>

        <div class="key-concept">
            <strong>延伸知識：AI 發展歷程中的「AI 寒冬」</strong><br>
            指 AI 發展史上，因技術瓶頸、過度吹捧的期望無法實現，導致研究資金和學術興趣大幅衰退的時期。這提醒我們 AI 發展並非一帆風順，而是經歷了多次的起伏。
        </div>

        <h4><span class="concept">機器學習 (Machine Learning, ML) 基礎</span></h4>
        
        <div class="key-concept">
            <strong>核心要素與運作原理</strong>：機器學習的核心在於使用<span class="highlight">數據 (Data)</span> 訓練<span class="highlight">模型 (Model)</span>，並透過<span class="highlight">損失函數 (Loss Function)</span> 評估模型性能。其目標是讓機器能夠從數據中學習，而<span class="highlight">無需明確編程</span>。
        </div>
        
        <div class="definition">
            <strong>關鍵概念區分</strong>：
            <ul>
                <li><strong class="technical-term">參數 (Parameters)</strong>：模型在訓練過程中<span class="highlight">自動學習到的數值</span>，例如線性迴歸中的斜率和截距。</li>
                <li><strong class="technical-term">超參數 (Hyperparameters)</strong>：模型訓練前需要<span class="highlight">手動設定的數值</span>，會影響模型訓練過程和性能，例如學習率或迭代次數。</li>
                <li><strong class="technical-term">特徵 (Features)</strong>：數據中用於<span class="highlight">描述樣本屬性的獨立變量或屬性</span>，例如房價預測中的房屋面積、臥室數量等。</li>
                <li><strong class="technical-term">標籤 (Labels)</strong>：在監督式學習中，每個輸入數據點所對應的<span class="highlight">正確輸出或目標值</span>，例如圖像識別中圖片裡物體的名稱。</li>
            </ul>
        </div>
        
        <div class="error-analysis">
            <strong class="important">錯題詳解</strong>：<strong>若一家超商根據天氣進貨，天氣是「特徵（輸入變數）」，那麼銷售數量是什麼？</strong>
            <ul>
                <li><strong class="important">正確答案：(B) 標籤（目標變數）</strong>。</li>
                <li><strong>解釋</strong>：在機器學習中，<strong class="technical-term">特徵 (Features) / 輸入變數 (Input Variables)</strong> 是你提供給模型進行學習和預測的數據。而<strong class="technical-term">標籤 (Labels) / 目標變數 (Target Variables) / 輸出變數 (Output Variables)</strong> 則是模型最終預測的結果。在監督式學習中，模型會學習如何從輸入特徵映射到這些標籤。</li>
                <li><strong class="analogy">白話比喻</strong>：如果你要預測一個人的體重，那麼他的身高、年齡、性別、飲食習慣等等，都是「特徵」或「輸入變數」。而「體重」這個數值就是你希望模型預測的「標籤」或「目標變數」或「輸出變數」。</li>
                <li><strong>其他選項為何不正確</strong>：
                    <ul>
                        <li>(A) 輸出變數：雖然廣義上來說，銷售數量是模型輸出的結果，但在描述訓練和預測的目標時，「標籤」或「目標變數」是更常用和精確的監督式學習術語。</li>
                        <li>(C) 雜訊：雜訊是指數據中的隨機誤差或不相關的資訊，會干擾模型的學習，而不是模型的目標。</li>
                        <li>(D) 權重：權重是模型在學習過程中調整的內部參數，用來決定不同特徵的重要性，而不是預測的結果本身。</li>
                    </ul>
                </li>
            </ul>
        </div>

        <h4><span class="concept">深度學習 (Deep Learning, DL)</span></h4>
        
        <div class="key-concept">
            <ul>
                <li><strong>核心與運作原理</strong>：深度學習使用<span class="highlight">多層次的類神經網路</span>來學習複雜的特徵，特別在處理圖片和聲音方面表現卓越。</li>
                <li><strong>與傳統機器學習模型的區別</strong>：神經網路透過<span class="highlight">多層結構學習數據的深層特徵</span>，這使得深度學習能夠自動從原始數據中提取高層次的抽象特徵，而傳統機器學習通常需要人工進行特徵工程。</li>
                <li><span class="application">實際應用範疇</span>：語音識別、自動駕駛、人臉識別、情感分析等。</li>
            </ul>
        </div>

        <div class="section-divider"></div>

        <h3>第二章：機器學習典範與演算法</h3>
        
        <h4><span class="concept">學習典範 (Paradigms)</span></h4>
        
        <div class="comparison">
            <h5><span class="technical-term">監督式學習 (Supervised Learning, SL)</span>：</h5>
            <ul>
                <li><strong>特點與運作原理</strong>：訓練數據集中<span class="highlight">包含標記信息</span>（即正確的「標籤」或「答案」），模型透過學習這些帶有標記的數據，來建立輸入與輸出之間的映射關係。主要用於<span class="highlight">分類和迴歸問題</span>。</li>
                <li><span class="application">實際應用範例</span>：電子郵件垃圾郵件過濾、圖像識別、智能溫控器調節。</li>
            </ul>
        </div>
        
        <div class="comparison">
            <h5><span class="technical-term">非監督式學習 (Unsupervised Learning, USL)</span>：</h5>
            <ul>
                <li><strong>特點與運作原理</strong>：僅需探索數據內部的結構，將數據分組或找出數據中的隱藏模式，<span class="highlight">無需預先標註</span>。模型旨在發現數據本身的結構或分佈。主要任務包括<span class="highlight">分群 (Clustering) 和降維 (Dimensionality Reduction)</span>。</li>
                <li><span class="application">實際應用範例</span>：<span class="highlight">客群分類</span>，透過分析客戶的購買行為、瀏覽習慣等數據，自動將他們分成不同的客戶群體，以便進行精準行銷。</li>
            </ul>
        </div>
        
        <div class="comparison">
            <h5><span class="technical-term">半監督式學習 (Semi-supervised Learning)</span>：</h5>
            <ul>
                <li><strong>特點與運作原理</strong>：結合了<span class="highlight">少量標註數據和大量無標註數據</span>進行訓練，以提高模型效能。這對於數據標註成本高昂的場景特別有用。</li>
            </ul>
        </div>
        
        <div class="comparison">
            <h5><span class="technical-term">強化學習 (Reinforcement Learning, RL)</span>：</h5>
            <ul>
                <li><strong>特點與運作原理</strong>：透過與環境互動，代理 (Agent) 根據<span class="highlight">獎勵與懲罰</span>調整策略，目標是最大化長期獎勵。適用於動態決策問題。</li>
                <li><strong class="analogy">白話比喻</strong>：想像這就像訓練一隻寵物，當它做出你希望的行為時，你給予獎勵；當它做出不當行為時，給予懲罰。久而久之，寵物就會學會如何做出最能獲得獎勵的行為。</li>
                <li><span class="application">實際應用範例</span>：訓練電腦下圍棋（如 Google DeepMind 的 AlphaGo），透過與自身對弈不斷學習和優化棋藝；自動駕駛，車輛透過感知環境、執行動作並從結果中學習，以安全高效地行駛。</li>
            </ul>
        </div>

        <h4><span class="concept">常見機器學習演算法與模型</span></h4>
        
        <div class="key-concept">
            <h5><span class="technical-term">K-Means 聚類演算法 (K-Means Clustering)</span>：</h5>
            <ul>
                <li><strong>K 的含義</strong>：K 代表希望將數據劃分的群組數量。</li>
                <li><strong>運作原理與特點</strong>：原理相對簡單。主要用於處理<span class="highlight">數值型資料</span>，希望找出 k 個互不交集的群集，使得每個群集內的點彼此相似，而不同群集間的點彼此相異。主要用途是解決<span class="highlight">聚類問題</span>，即將數據分組，例如客戶細分、文檔歸類。</li>
                <li><strong class="important">限制</strong>：不同的起始群集中心，可能會造成不同的分群結果。容易受雜訊與離群值 (Outlier) 影響其群集中心。不適合非球形、數據密度變化大或有離群數據的集群問題。</li>
            </ul>
        </div>
        
        <div class="key-concept">
            <h5><span class="technical-term">線性迴歸 (Linear Regression)</span>：</h5>
            <ul>
                <li><strong>運作原理與用途</strong>：一種用於<span class="highlight">預測連續數值型輸出</span>的統計模型，它假設輸入變量和輸出變量之間存在線性關係。</li>
                <li><span class="application">實際應用範例</span>：<span class="highlight">銷售額預測</span>、房價預測、股票價格預測等。</li>
            </ul>
        </div>
        
        <div class="key-concept">
            <h5><span class="technical-term">決策樹 (Decision Tree)</span>：</h5>
            <ul>
                <li><strong>運作原理與優勢</strong>：透過一系列的判斷規則來做出預測或分類，形成樹狀結構。其最大的優勢是<span class="highlight">具有良好的可解釋性</span>，模型易於理解和解釋，決策路徑清晰可見。</li>
                <li><strong class="analogy">白話比喻</strong>：想像銀行審批貸款，決策樹會像一個流程圖，先問「年收入是否大於100萬？」，再問「是否有信用違約？」，最終給出「批准」或「拒絕」的結論。</li>
                <li><span class="application">實際應用範例</span>：客戶流失預測、醫療診斷輔助。</li>
            </ul>
        </div>
        
        <div class="key-concept">
            <h5><span class="technical-term">隨機森林 (Random Forest)</span>：</h5>
            <ul>
                <li><strong>運作原理</strong>：透過<span class="highlight">集成多棵隨機生成的決策樹並投票</span>（用於分類）或取平均值（用於迴歸）來進行預測，從而改進單一決策樹容易過擬合和不穩定的缺陷。它利用了「群體的智慧」來提高模型的準確性和穩定性。</li>
                <li><strong class="analogy">白話比喻</strong>：想像你要做出一個重要的決定，你不只問一個人的意見，而是問了「一群獨立思考的專家（多棵決策樹）」，然後綜合所有專家的意見（投票或取平均），最終做出最明智的決定。這比只聽一個專家的意見要可靠得多。</li>
                <li><span class="application">實際應用範例</span>：欺詐檢測、圖像分類。</li>
            </ul>
        </div>
        
        <div class="error-analysis">
            <strong class="important">錯題詳解</strong>：<strong>隨機森林演算法屬於哪種類型的演算法？</strong>
            <ul>
                <li><strong class="important">正確答案：(B) 集成學習</strong>。</li>
                <li><strong>解釋</strong>：隨機森林是一種<span class="highlight">集成學習 (Ensemble Learning)</span> 方法。它不是單一的決策樹，而是由許多獨立訓練的決策樹組成的「森林」。當需要做預測時，每棵樹都會給出一個答案，然後綜合所有樹的答案，得出最終的結果。集成學習結合了多個「弱學習器」，以共同解決同一個問題，從而獲得比單一模型更好的預測性能。</li>
                <li><strong>其他選項為何不正確</strong>：
                    <ul>
                        <li>(A) 判別式學習：隨機森林本身是一種判別式模型，但「判別式學習」是它實現的「目標」或「功能」範疇，而不是它本身的「演算法類型」。集成學習是更精確的分類。</li>
                        <li>(C) 強化學習：這是透過「試錯」和「獎勵/懲罰」學習的方式。隨機森林與此概念無關。</li>
                        <li>(D) 非監督式學習：非監督式學習是從沒有標籤的數據中學習模式或結構。隨機森林需要帶標籤的數據進行訓練，因此不屬於非監督式學習。</li>
                    </ul>
                </li>
            </ul>
        </div>
        
        <div class="key-concept">
            <h5><span class="technical-term">梯度下降 (Gradient Descent)</span>：</h5>
            <ul>
                <li><strong>運作原理與用途</strong>：一種<span class="highlight">優化演算法</span>，主要用於<span class="highlight">優化模型參數以最小化損失函數</span>。它透過迭代地調整參數，沿著損失函數梯度下降的方向移動，直到找到損失函數的最小值。</li>
                <li><span class="application">實際應用範例</span>：在訓練神經網絡和許多機器學習模型時，都用梯度下降來調整模型權重。</li>
            </ul>
        </div>
        
        <div class="key-concept">
            <h5><span class="technical-term">支援向量機 (Support Vector Machine, SVM)</span>：</h5>
            <ul>
                <li><strong>運作原理與用途</strong>：一種用於<span class="highlight">分類和迴歸問題</span>的機器學習模型，它在高維空間中構造一個或一組超平面，用以進行分類或迴歸。</li>
                <li><span class="application">實際應用範例</span>：文本分類、手寫數字識別。</li>
            </ul>
        </div>
        
        <div class="key-concept">
            <h5><span class="technical-term">卷積神經網絡 (Convolutional Neural Network, CNN)</span>：</h5>
            <ul>
                <li><strong>運作原理與擅長處理</strong>：一種設計用於處理序列數據的深度學習模型，具有「記憶」能力，可以利用序列中先前的信息。主要擅長處理<span class="highlight">序列數據</span>，如文字、語音。</li>
                <li><span class="application">實際應用範例</span>：語音識別、自然語言翻譯。</li>
                <li><strong>延伸知識：長短期記憶網絡 (LSTM)</strong> 是 RNN 的改進版本，能更好地處理長序列依賴，解決了 RNN 的梯度消失/爆炸問題。</li>
            </ul>
        </div>

        <div class="key-concept">
            <h5><span class="technical-term">循環神經網絡 (Recurrent Neural Network, RNN)</span>：</h5>
            <ul>
                <li><strong>運作原理與擅長處理</strong>：一種專門設計用於處理網格狀數據（如圖像）的深度學習模型，透過卷積層自動提取圖像的空間特徵。主要擅長處理<span class="highlight">序列數據</span>，圖像數據</li>
                <li><span class="application">實際應用範例</span>：圖像識別、物件檢測、人臉識別。</li>
                <li><strong>延伸知識：長短期記憶網絡 (LSTM) 是 RNN 的改進版本，能更好地處理長序列依賴，解決了 RNN 的梯度消失/爆炸問題。</li>
            </ul>
        </div>

        <div class="error-analysis">
            <strong class="important">錯題詳解</strong>：<strong>邏輯迴歸（Logistic Regression）雖名為迴歸，但它通常應用於哪種類型的問題？</strong>
            <ul>
                <li><strong class="important">正確答案：(B) 二元分類（Binary Classification）</strong>。</li>
                <li><strong>解釋</strong>：儘管名稱中有「迴歸」，但邏輯迴歸主要用於<span class="highlight">分類問題</span>。它特別擅長處理<span class="highlight">二元分類</span>，也就是預測結果只有兩個類別（例如：是/否，真/假，陽性/陰性）。它透過一個「S」形的邏輯函數將連續的輸入值映射到一個介於 0 到 1 之間的機率值，然後再根據這個機率值判斷屬於哪個類別。</li>
                <li><strong class="analogy">白話比喻</strong>：想像你要預測一個人會不會買你的產品，結果只有「會買」或「不會買」兩種。邏輯迴歸就像一個「銷售預測機」，它會計算出客戶「會買」的機率是多大（例如 0.8），然後如果機率高於一個門檻（例如 0.5），就判斷他「會買」。</li>
                <li><strong>其他選項為何不正確</strong>：
                    <ul>
                        <li>(A) 預測連續數值：這是迴歸問題的範疇，例如線性迴歸。</li>
                        <li>(C) 資料降維：這是非監督式學習的一種，例如主成分分析（PCA）。</li>
                        <li>(D) 聚類分析：這是非監督式學習的一種，用於將數據分組，例如 K-Means。</li>
                    </ul>
                </li>
            </ul>
        </div>

        <h4><span class="concept">模型性能與問題</span></h4>
        
        <div class="key-concept">
            <h5><span class="technical-term">過擬合 (Overfitting)</span>：</h5>
            <ul>
                <li><strong class="important">主要原因</strong>：模型<span class="highlight">過度學習訓練數據中的雜訊</span>，導致在訓練數據上表現良好，但在新的、未見過的數據（測試數據）上泛化能力差。</li>
                <li><strong class="analogy">白話比喻</strong>：就像一個學生只會死背考古題的答案，卻不理解背後的原理。在考古題（訓練數據）上能拿滿分，但一到正式考試（新數據），題目稍作變化就完全不會了。</li>
                <li><strong>降低風險的方法</strong>：增加<span class="highlight">正則化項</span>，以懲罰複雜模型，防止模型過度擬合訓練數據；增加<span class="highlight">訓練數據量</span>，讓模型見到更多數據，學習到更普遍的模式。</li>
            </ul>
        </div>
        
        <div class="key-concept">
            <h5><span class="technical-term">交叉驗證 (Cross-validation)</span>：</h5>
            <ul>
                <li><strong>目的與運作原理</strong>：一種統計方法，用於<span class="highlight">評估模型的泛化能力</span>並<span class="highlight">降低過擬合風險</span>。它將數據集分成多個子集，輪流將其中一部分作為訓練集，另一部分作為測試集進行評估。</li>
            </ul>
        </div>
        
        <div class="key-concept">
            <h5><span class="concept">模型評估指標</span>：</h5>
            <ul>
                <li><strong class="technical-term">MSE (Mean Squared Error)</strong>：在機器學習中常用作迴歸模型的<span class="highlight">損失函數</span>或<span class="highlight">評估指標</span>，衡量預測值與真實值之間平方差的均值。</li>
                <li><strong class="technical-term">召回率 (Recall) 和 精確率 (Precision)</strong>：主要用於評估<span class="highlight">分類模型</span>，特別是處理不平衡數據集時。
                    <ul>
                        <li><strong>精確率</strong>：模型預測為正例的樣本中，有多少是真正的正例。</li>
                        <li><strong>召回率</strong>：所有真正的正例中，有多少被模型正確地識別出來。</li>
                        <li><strong class="analogy">白話比喻</strong>：假設一個 AI 用於機場安檢中檢測危險品。<span class="highlight">高精確率</span>意味著 AI 報警時，基本上都是真的危險品，但可能會漏掉一些危險品。<span class="highlight">高召回率</span>意味著 AI 能找出所有真正的危險品，即使這意味著會有一些誤報（把無害物品當成危險品）。在不同場景下，需要權衡兩者的重要性。</li>
                    </ul>
                </li>
                <li><strong class="technical-term">F1分數 (F1-score)</strong>：是精確率和召回率的<span class="highlight">調和平均數</span>，綜合評估模型性能，特別適用於類別不平衡問題。</li>
                <li><strong class="technical-term">曲線下面積 (AUC, Area Under the Curve)</strong>：衡量分類模型在所有可能分類閾值下的表現，數值越高表示模型性能越好。</li>
            </ul>
        </div>
        
        <div class="error-analysis">
            <strong class="important">錯題詳解</strong>：<strong>某公司希望導入AI系統協助預測銷售趨勢，請問最適合使用哪一種模型？</strong>
            <ul>
                <li><strong class="important">正確答案：(B) 回歸模型</strong>。</li>
                <li><strong>解釋</strong>：預測銷售趨勢意味著公司希望能夠預測未來的銷售額，這個銷售額是一個<span class="highlight">連續的數值</span>（例如：下個月的銷售額會是 100 萬、200 萬，或者 150.5 萬等）。<span class="highlight">回歸模型 (Regression Model)</span> 正是用於預測連續數值的目標變數。</li>
                <li><strong class="analogy">白話比喻</strong>：就像你希望預測明天的氣溫會是多少度，或者你的體重會是多少公斤，這些都是連續的、可以有小數點的數值，這正是回歸模型擅長的任務。</li>
                <li><strong>其他選項為何不正確</strong>：
                    <ul>
                        <li>(A) 分類模型：用於將數據點歸類到預先定義的離散類別中（例如：判斷圖片是貓還是狗）。不適用於預測連續的銷售額。</li>
                        <li>(C) 聚類模型：是一種非監督式學習模型，用於將數據點自動分組到相似的群集中。不適用於預測具體的銷售額數值。</li>
                        <li>(D) 樹狀圖模型：雖然樹狀圖模型可以應用於迴歸問題（迴歸樹），但「迴歸模型」是更直接且涵蓋範圍更廣的類別，而「樹狀圖模型」只是實現迴歸或分類的一種具體演算法「類型」。</li>
                    </ul>
                </li>
            </ul>
        </div>

        <div class="section-divider"></div>

        <h3>第三章：數據與資料分析</h3>
        
        <h4><span class="concept">數據類型與分布</span></h4>
        
        <div class="key-concept">
            <ul>
                <li><strong class="technical-term">類別型數據 (Categorical Data)</strong>：表示類別或組別的數據，例如<span class="highlight">性別 (男/女)</span>、血型 (A/B/AB/O)。決策樹等模型可以直接處理類別型資料。</li>
                <li><strong class="technical-term">數值型數據 (Numerical Data)</strong>：表示數值或量的數據，例如<span class="highlight">年齡</span>、溫度、身高。</li>
            </ul>
        </div>
        
        <div class="key-concept">
            <h5><span class="concept">數據分布估計與工具</span>：</h5>
            <ul>
                <li><strong>適合的工具</strong>：<span class="highlight">直方圖 (Histogram)</span> 最適合用於資料分佈估計，它能視覺化數據的頻率分佈和集中趨勢。</li>
                <li><strong class="important">不適合的工具</strong>：<span class="highlight">雷達圖 (Radar chart)</span> 主要用於比較多個維度上的表現，而非呈現單一維度的分布情況。</li>
            </ul>
        </div>
        
        <div class="key-concept">
            <h5><span class="concept">集中趨勢描述</span>：</h5>
            <ul>
                <li><strong class="technical-term">中位數 (Median)</strong>：最適合描述資料中包含<span class="highlight">少數極端值</span>（如豪宅的極端高價）的情況，因為中位數不受極端值影響，更能代表數據的「中間」趨勢。</li>
                <li><strong class="technical-term">眾數 (Mode)</strong>：最適合描述資料中<span class="highlight">某種產品銷量遠高於其他產品</span>（出現頻率最高的數值）的情況，它表示數據集中出現次數最多的值。</li>
            </ul>
        </div>
        
        <div class="key-concept">
            <h5><span class="technical-term">數據偏態 (Skewness)</span>：</h5>
            <ul>
                <li><span class="highlight">平均數 < 中位數</span>：通常表示資料為<span class="highlight">負偏態分布</span>，數據的尾部偏向左側 (較小值)。</li>
                <li><span class="highlight">平均數 > 中位數</span>：通常表示資料為<span class="highlight">正偏態分布</span>，數據的尾部偏向右側 (較大值)。</li>
            </ul>
        </div>
        
        <div class="key-concept">
            <h5><span class="technical-term">四分位距 (IQR, Interquartile Range)</span>：</h5>
            <ul>
                <li><strong>定義與特性</strong>：是第三四分位數 (Q3) 與第一四分位數 (Q1) 的差。它衡量中間 50% 數據的範圍，<span class="highlight">不受極端值影響</span>，是比全距 (Range) 更穩健的變異性度量。</li>
            </ul>
        </div>

        <h4><span class="concept">數據處理與管理</span></h4>
        
        <div class="key-concept">
            <h5><span class="technical-term">大數據 (Big Data)</span>：</h5>
            通常具有<span class="highlight">數量 (Volume)、速度 (Velocity)、多樣性 (Variety)</span> 三個主要特性 (3V)。
            <div class="example">
                <strong class="analogy">白話比喻</strong>：
                <ul>
                    <li><span class="highlight">數量 (Volume)</span>：想像你不是只有一個裝滿小石子的桶子，而是有「一整座山那麼多的沙子」。</li>
                    <li><span class="highlight">速度 (Velocity)</span>：想像這些沙子不是靜止不動的，而是像「洪水一樣不斷地湧過來」。</li>
                    <li><span class="highlight">多樣性 (Variety)</span>：想像這些沙子不只是普通的沙子，裡面還夾雜著「各種不同形狀、顏色、材質的小石頭」。</li>
                </ul>
            </div>
        </div>
        
        <div class="error-analysis">
            <strong class="important">錯題詳解</strong>：<strong>大數據（Big Data）的3V特性不包括？</strong>
            <ul>
                <li><strong class="important">正確答案：(C) Value（價值）</strong>。</li>
                <li><strong>解釋</strong>：大數據的經典 3V 特性是指資料的<span class="highlight">巨量 (Volume)</span>、<span class="highlight">快速 (Velocity)</span> 和<span class="highlight">多樣 (Variety)</span>。雖然「價值 (Value)」是大數據分析的最終目標和驅動力，但它本身<span class="highlight">不被視為數據本身的固有「特性」</span>，而是從數據中可以「提取」的結果。</li>
                <li><strong>其他選項為何不正確</strong>：(A) Volume（巨量）、(B) Velocity（快速）、(D) Variety（多樣）都是經典 3V 之一。</li>
            </ul>
        </div>
        
        <div class="key-concept">
            <h5><span class="technical-term">資料清洗 (Data Cleaning)</span>：</h5>
            <ul>
                <li><strong>運作原理與目的</strong>：主要目的是<span class="highlight">移除或修正數據中的錯誤、不一致或缺失值</span>，確保資料乾淨正確、可用於分析和模型訓練。</li>
            </ul>
        </div>
        
        <div class="key-concept">
            <h5><span class="technical-term">OSEMN 流程 (AI 專案中的數據處理流程)</span>：</h5>
            <ul>
                <li><strong>O (Obtain)</strong>：<span class="highlight">獲取數據</span>，從各種來源收集所需的數據。</li>
                <li><strong>S (Scrub) / E (Explore)</strong>：<span class="highlight">數據清洗與探索</span>，處理缺失值、異常值，並對數據進行初步分析和視覺化，以了解數據特性。</li>
                <li><strong>M (Model)</strong>：<span class="highlight">模型建立</span>，選擇合適的機器學習模型並進行訓練。</li>
                <li><strong>E (Evaluate)</strong>：<span class="highlight">評估模型</span>，使用評估指標和交叉驗證等方法，評估模型的性能和泛化能力。</li>
                <li><strong>N (iNfer)</strong>：<span class="highlight">歸納，將訓練好的模型應用到新數據上</span>，進行預測或決策，並持續監控模型表現。</li>
            </ul>
        </div>
        
        <div class="key-concept">
            <h5><span class="technical-term">ETL (Extract, Transform, Load)</span>：</h5>
            資料處理流程中的「T」代表<span class="highlight">轉換 (Transform)</span>，指將提取的數據轉換為適合分析和儲存的格式。
        </div>
        
        <div class="key-concept">
            <h5><span class="concept">數據結構與管理 (延伸知識)</span>：</h5>
            <ul>
                <li><strong>基本組成部分</strong>：索引、記錄、欄位（<span class="important">變數不是</span>）。</li>
                <li><strong>數據表關聯性</strong>：一對一、一對多、多對多（<span class="important">不包括多對單</span>）。</li>
                <li><strong class="technical-term">索引 (Index)</strong>：在電商數據管理中，需要索引以<span class="highlight">快速檢索數據</span>，提高查詢效率。</li>
            </ul>
        </div>
        
        <div class="key-concept">
            <h5><span class="technical-term">特徵工程 (Feature Engineering)</span>：</h5>
            <ul>
                <li><strong>運作原理與重要性</strong>：<span class="highlight">創造或選擇最能代表數據本質的「特徵」</span>，以提升模型性能。這通常需要領域知識，將原始數據轉換為模型更容易理解和學習的形式。</li>
                <li><strong>影響</strong>：了解數據分佈和特徵有助於<span class="highlight">選擇合適的特徵</span>。</li>
            </ul>
        </div>
        
        <div class="error-analysis">
            <strong class="important">錯題詳解</strong>：<strong>資料轉換（Data Transformation）中，「特徵標準化（Standardization）」的目的是什麼？</strong>
            <ul>
                <li><strong class="important">正確答案：(A) 將數據轉換為均值為0、標準差為1的分布</strong>。</li>
                <li><strong>解釋</strong>：特徵標準化（Standardization，又稱 Z-score Normalization）是一種數據預處理技術，它將數據集中的每個特徵調整，使得它們的<span class="highlight">平均值（均值）變為 0，並且標準差變為 1</span>。主要目的是消除量綱影響，確保所有特徵在模型中具有公平的影響力，並加速模型收斂。</li>
                <li><strong class="analogy">白話比喻</strong>：想像一群來自不同國家的人參加跑步比賽，每個人都有自己的身高和體重（原始數據）。標準化就像是給每個人「統一度量衡」，把他們的身高和體重都換算成相對的「標準分數」，這樣無論誰來自哪裡，他們在比賽中的「影響力」都會在一個公平的起跑線上。</li>
                <li><strong>其他選項為何不正確</strong>：
                    <ul>
                        <li>(B) 增強圖像邊緣：這是圖像處理中的濾波或增強技術的目的，與數據標準化無關。</li>
                        <li>(C) 將數據壓縮到固定範圍內：這是<span class="highlight">正規化（Normalization，通常指 Min-Max Scaling）</span>的目的，它通常將數據縮放到 [0,1] 或 [-1, 1] 等固定範圍，與標準化不同。</li>
                        <li>(D) 增加資料筆數：這是<span class="highlight">數據增強（Data Augmentation）</span>的目的，用於擴展數據集，通常在圖像或文本數據中應用。</li>
                    </ul>
                </li>
            </ul>
        </div>
        
        <div class="comparison">
            <h5><span class="concept">驗證性資料分析 (CDA) 與 探索性資料分析 (EDA) (比較)</span>：</h5>
            <ul>
                <li><strong class="technical-term">CDA</strong>：主要著重於<span class="highlight">驗證先前生成的假設並進行深入挖掘</span>。</li>
                <li><strong class="technical-term">EDA</strong>：主要著重於對資料進行初步描述和視覺化，探索數據中潛在的模式和異常，<span class="highlight">沒有預設假設</span>。</li>
            </ul>
        </div>
        
        <div class="error-analysis">
            <strong class="important">錯題詳解</strong>：<strong>探索性資料分析（EDA）的主要目的是什麼？</strong>
            <ul>
                <li><strong class="important">正確答案：(C) 了解資料的分布與特性</strong>。</li>
                <li><strong>解釋</strong>：EDA 是資料分析過程中的一個初步階段，它利用統計圖形和圖表來<span class="highlight">視覺化、總結資料集的關鍵特徵，並從中發現模式、異常、關係，以及檢查假設</span>。它的目標是在沒有任何預設模型的情況下，深入了解資料本身。</li>
                <li><strong class="analogy">白話比喻</strong>：想像你剛拿到一份陌生的人口普查資料。在正式分析之前，你會先「大致瀏覽」一下，看看年齡分佈是怎麼樣的？男女比例如何？有沒有什麼特別奇怪的數據？這個「初步的了解和探索」的過程就是 EDA。你不是直接去預測哪個地區的收入會最高，而是先搞清楚所有收入數據的整體樣貌。</li>
                <li><strong>其他選項為何不正確</strong>：
                    <ul>
                        <li>(A) 建立深度學習模型：建立模型是資料分析流程的<span class="highlight">後續階段</span>，在 EDA 之後才會進行。</li>
                        <li>(B) 預測未來結果：預測是模型的應用目的，通常在模型建立並訓練完成後才進行。</li>
                        <li>(D) 清理雜訊資料：資料清理是資料預處理的一部分，雖然 EDA 可以幫助<span class="highlight">識別</span>需要清理的雜訊，但清理本身是另一個獨立的步驟。</li>
                    </ul>
                </li>
            </ul>
        </div>
        
        <div class="key-concept">
            <h5><span class="technical-term">數據偏見 (Data Bias)</span>：</h5>
            <ul>
                <li><strong>定義</strong>：模型在訓練過程中學習到<span class="highlight">不公平或歧視性的模式</span>。</li>
                <li><strong>原因</strong>：訓練資料來源存在種族、性別、年齡、宗教、性取向等因素，或因為在地、小眾等語料的欠缺。</li>
                <li><span class="application">實際案例</span>：亞馬遜曾開發一套 AI 招聘工具，但後來發現該工具對女性求職者存在歧視。原因是模型學習的歷史數據中，成功的技術人員大多是男性，導致模型學會了「男性是更好的工程師」這種偏見。這個案例凸顯了數據偏見的嚴重性。</li>
            </ul>
        </div>

        <div class="section-divider"></div>

        <h3>第四章：生成式AI核心技術與原理</h3>
        
        <h4><span class="concept">生成式AI (Generative AI, GAI) 定義與核心</span></h4>
        
        <div class="definition">
            <ul>
                <li><strong>定義</strong>：最核心的能力是<span class="highlight">生成新的、原創的內容</span>，如圖像、文本或音樂。</li>
                <li><strong>核心基礎</strong>：其發展的重要基礎是<span class="highlight">神經網路（深度學習模型）</span>。</li>
                <li><span class="application">實際應用領域</span>：可廣泛應用於文學創作、藝術設計、音樂創作等領域。</li>
            </ul>
        </div>
        
        <div class="comparison">
            <h5><span class="concept">與鑑別式 AI 的區別 (比較)</span>：</h5>
            <ul>
                <li><strong class="technical-term">生成式 AI</strong>：專注於<span class="highlight">生成新的內容</span>。</li>
                <li><strong class="technical-term">鑑別式 AI (Discriminative AI)</strong>：主要目標是<span class="highlight">分類或迴歸數據</span>，專注於區分或預測現有數據的類別或數值。</li>
                <li><strong>範例比較</strong>：生成式 AI 可以生成一張貓的圖片，而鑑別式 AI 則是用來判斷一張圖片中是否有貓。</li>
                <li><strong>整合應用</strong>：生成式 AI 也可以支援鑑別式 AI，例如<span class="highlight">模擬交通場景以訓練自動駕駛模型</span>，生成數據來彌補數據稀缺或不平衡的問題。</li>
            </ul>
        </div>
        
        <div class="error-analysis">
            <strong class="important">錯題詳解</strong>：<strong>鑑別式AI（Discriminative AI）的原理是什麼？</strong>
            <ul>
                <li><strong class="important">正確答案：(B) 學習不同類別資料之間的「決策邊界」</strong>。</li>
                <li><strong>解釋</strong>：鑑別式模型的目標是直接學習輸入數據（$X$）到輸出標籤（$Y$）的映射關係，即 $P(Y|X)$。它們專注於區分不同類別，找出最佳的「決策邊界」或「分離超平面」，來將不同類別的數據分開。它們不關心數據是如何生成的，只關心如何區分它們。</li>
                <li><strong class="analogy">白話比喻</strong>：想像你有兩堆水果：蘋果和橘子。鑑別式AI就像一個「水果分類員」，它學習的是「如何區分蘋果和橘子」，它會找出一個判斷規則（決策邊界），例如「圓的、紅色的是蘋果；圓的、橙色的是橘子」。它不需要知道蘋果或橘子是如何長出來的，只要能正確分開它們就行。</li>
                <li><strong>其他選項為何不正確</strong>：
                    <ul>
                        <li>(A) 生成新的數據：這是<span class="highlight">生成式AI (Generative AI) / 生成式模型</span>的原理。</li>
                        <li>(C) 根據已有的輸入序列預測下一個最有可能出現的詞元：這是<span class="highlight">語言模型</span>的任務，通常是生成式模型的一個功能。</li>
                        <li>(D) 透過嘗試與犯錯來學習最優策略：這是<span class="highlight">強化學習 (Reinforcement Learning)</span> 的原理。</li>
                    </ul>
                </li>
            </ul>
        </div>

        <h4><span class="concept">生成式AI模型</span></h4>
        
        <div class="key-concept">
            <h5><span class="technical-term">生成對抗網路 (Generative Adversarial Network, GAN)</span>：</h5>
            <ul>
                <li><strong>組成與運作原理</strong>：由<span class="highlight">生成器 (Generator)</span> 和<span class="highlight">鑑別器 (Discriminator)</span> 兩個網路組成。這兩個模型互相競爭：生成器嘗試生成足以欺騙鑑別器的逼真內容；鑑別器嘗試區分真實內容和生成器生成的「假」內容。透過這種<span class="highlight">對抗性訓練</span>，兩者能力不斷提升，最終生成器能產生高度逼真的內容。</li>
                <li><strong class="analogy">白話比喻</strong>：這是一個「道高一尺，魔高一丈」的過程：生成器努力創造逼真的假數據（如假畫），鑑別器則努力學習如何分辨真假。兩者相互競爭、共同進化，最終生成器能創造出足以以假亂真的高品質數據。</li>
                <li><strong>代表模型</strong>：GAN 是生成式 AI 的代表模型之一。</li>
                <li><strong>延伸知識</strong>：其訓練穩定性問題可透過<span class="highlight">Waserstein GAN (WGAN)</span> 等改進模型來解決。</li>
                <li><span class="application">實際應用範例</span>：生成逼真人臉、圖像風格轉換、超解析度圖像生成。</li>
            </ul>
        </div>
        
        <div class="key-concept">
            <h5><span class="technical-term">變分自編碼器 (Variational Autoencoder, VAE)</span>：</h5>
            <ul>
                <li><strong>主要用途</strong>：<span class="highlight">圖像生成與數據重建</span>。</li>
                <li><span class="application">實際應用範例</span>：圖像去噪、人臉變換、生成新的藝術作品。</li>
            </ul>
        </div>
        
        <div class="key-concept">
            <h5><span class="technical-term">大型語言模型 (Large Language Model, LLM)</span>：</h5>
            <ul>
                <li><strong>功能與運作原理</strong>：主要用於<span class="highlight">理解、生成和處理大量人類語言</span>。它們透過<span class="highlight">大量文本數據訓練</span>來學習語言模式和知識。</li>
                <li><strong>與一般語言模型的差異</strong>：LLM 具備<span class="highlight">更強的語言理解和生成能力</span>，因為它們在更大的數據集上訓練，擁有更多參數，能夠捕捉更複雜的語義和上下文關係。</li>
                <li><span class="application">實際應用範疇</span>：文字分類、文本摘要、文本比較、內容創作等 NLP 任務。</li>
            </ul>
        </div>
        
        <div class="definition">
            <h5><span class="concept">運作原理補充</span>：</h5>
            <ul>
                <li><strong>預測輸出詞元 (Tokens)</strong>：模型旨在預測單個詞元作為其輸出，被預測的詞元會被併入下一次迭代的輸入中，形成不斷擴展的視窗模式，從而生成連貫的文本。</li>
                <li><strong class="technical-term">詞元 (Tokens)</strong>：本質上是<span class="highlight">一塊文本，長度可變，通常由一串字元組成</span>，是模型處理語言的最小單位。</li>
                <li><strong>GPT 模型訓練</strong>：在訓練階段使用大量文本，進行<span class="highlight">無監督式學習</span>。</li>
            </ul>
        </div>
        
        <div class="key-concept">
            <h5><span class="concept">延伸知識與相關技術</span>：</h5>
            <ul>
                <li><strong class="technical-term">RLHF (Reinforcement Learning with Human Feedback)</strong>：透過強化學習與人類回饋，以提升大型語言模型的安全性和回應品質，使其輸出更符合人類偏好。</li>
            </ul>
        </div>
        
        <div class="error-analysis">
            <strong class="important">錯題詳解</strong>：<strong>Alignment方法中哪個技術用來微調生成模型？</strong>
            <ul>
                <li><strong class="important">正確答案：(A) RLHF（人類回饋強化學習）</strong>。</li>
                <li><strong>解釋</strong>：<span class="highlight">Alignment</span> 是指讓 AI 系統的行為、目標和輸出，與人類的價值觀、意圖和期望保持一致。<span class="highlight">RLHF (Reinforcement Learning from Human Feedback)</span> 是目前主流且最有效的對齊技術之一，特別用於微調大型語言模型。它透過人類對模型生成輸出的偏好打分，訓練一個獎勵模型，再用強化學習來微調原始生成模型，使其生成能最大化人類偏好的輸出。</li>
                <li><strong class="analogy">白話比喻</strong>：想像你訓練了一隻非常聰明但不聽話的狗。Alignment 就是要教它「聽從指令，做正確的事」。RLHF 就像你讓它做幾個動作，然後你作為主人（人類回饋）告訴它「這個動作做得好，有獎勵；那個動作做不好，沒獎勵」。然後，你再找一個「評分員」（獎勵模型），他學會了你的評分標準。最後，你讓狗不斷練習，努力去做到評分員覺得「最好」的動作。</li>
                <li><strong>其他選項為何不正確</strong>：
                    <ul>
                        <li>(B) OCR (Optical Character Recognition, 光學字符識別)：是一種將圖像中的文字轉換成可編輯文本的技術，與微調生成模型或 Alignment 無關。</li>
                        <li>(C) SVM (Support Vector Machine, 支援向量機)：是一種監督式學習演算法，主要用於分類和迴歸，不是用來對齊生成模型的特定方法。</li>
                        <li>(D) Dropout：是一種在神經網路訓練中使用的<span class="highlight">正則化技術</span>，目的是防止模型過擬合。它與模型對齊行為無關。</li>
                    </ul>
                </li>
            </ul>
        </div>
        
        <div class="key-concept">
            <ul>
                <li><strong class="technical-term">Adapter (如 LoRA)</strong>：在微調時只調整少量新參數，保持模型與預訓練的相似性，同時大幅減少運算量，這使得在有限資源下也能高效地微調大型模型。</li>
                <li><strong class="technical-term">LLaMA (Meta)</strong>：Meta 發布的 LLaMA 模型開放了預訓練參數，<span class="highlight">開啟了「人人都能微調」的時代</span>，促進了開源 LLM 的發展。</li>
                <li><strong class="technical-term">InstructGPT (ChatGPT 的前身)</strong>：OpenAI 的 InstructGPT 透過真實用戶數據的指令微調，顯著提升了模型表現和人類喜好度。</li>
                <li><strong class="technical-term">小型語言模型 (SLM)</strong>：相較於 LLM，SLM 具有<span class="highlight">低資源消耗且具備即時應用潛力</span>的優勢，適合部署在資源受限的設備或需要快速回應的場景。</li>
                <li><strong class="technical-term">PPO (Proximal Policy Optimization)</strong>：一種<span class="highlight">穩定且常用的強化學習演算法</span>，用於強化學習場景中策略更新，例如在 RLHF 中優化 LLM 的行為。</li>
                <li><strong class="technical-term">ReAct</strong>：一種<span class="highlight">結合推理與行動策略的 AI 決策流程框架</span>，允許模型同時「思考」（Reasoning）與「執行」（Acting），提高其處理複雜任務的能力。</li>
            </ul>
        </div>

        <h4><span class="technical-term">Transformer 模型</span></h4>
        
        <div class="key-concept">
            <ul>
                <li><strong>核心架構與關鍵貢獻</strong>：是現代大型語言模型（如 GPT、Gemini、Claude）運作的<span class="highlight">核心原理</span>。其最大的貢獻是引入了<span class="highlight">注意力機制 (Attention Mechanism)</span>，能更好地處理長距離依賴關係，解決了傳統 RNN 處理長序列時的限制。</li>
                <li><strong>核心組件與運作原理</strong>：由<span class="highlight">編碼器 (Encoder)</span> 與<span class="highlight">解碼器 (Decoder)</span> 組成，這兩個部分都利用了注意力機制。</li>
                <li><strong>理解輸入文字</strong>：透過將文本分割為<span class="highlight">Tokens</span>並計算它們之間的關係來理解，利用<span class="highlight">自注意力機制 (Self-Attention)</span> 捕捉單詞與其他單詞的關聯性，從而理解上下文信息。</li>
                <li><strong>理解序列順序</strong>：透過<span class="highlight">位置編碼 (Positional Encoding)</span> 來學習輸入序列的順序信息，彌補了注意力機制本身不具備順序性的缺點。</li>
                <li><strong>解碼器生成單詞</strong>：利用注意力機制計算關鍵標記的影響，逐步生成輸出文本。</li>
                <li><strong>延伸知識</strong>：在編碼器-解碼器架構中，早期的編碼器通常使用<span class="highlight">循環神經網路 (RNN)</span>。最簡單的輸出詞元選擇方法是<span class="highlight">貪婪搜索 (Greedy Search)</span>，每次都選擇機率最高的詞元。</li>
            </ul>
        </div>

        <h4><span class="technical-term">語彙基元化 (Tokenization)</span></h4>
        
        <div class="key-concept">
            <ul>
                <li><strong>目的與運作原理</strong>：在 Transformer 訓練中的主要目的是<span class="highlight">將文本拆分為最小單位 (Tokens)</span>，讓模型更好理解語言。它將原始文本轉換為模型可以處理的數字標記，使得 Transformer 模型能夠更靈活地處理複雜語義。</li>
                <li><strong>對 NLP 的重要性</strong>：允許模型<span class="highlight">識別和處理不同的詞語和語義單元</span>，是自然語言處理的基石。</li>
            </ul>
        </div>

        <h4><span class="concept">生成式AI相關技術與概念</span></h4>
        
        <div class="key-concept">
            <ul>
                <li><strong>生成音樂和圖像的技術</strong>：變分自編碼器 (VAE)、生成式對抗網路 (GAN)、自回歸模型 (如 Transformer) 皆可用於生成音樂和圖像。</li>
            </ul>
        </div>
        
        <div class="comparison">
            <h5><span class="concept">預訓練 (Pre-trained) 和 微調 (Fine-tuned) (比較)</span>：</h5>
            <ul>
                <li><strong class="technical-term">預訓練</strong>：先使用<span class="highlight">大型數據集</span>為一般用途預先訓練一個基礎模型，使其具備廣泛的知識和能力。</li>
                <li><strong class="technical-term">微調</strong>：然後使用<span class="highlight">小得多的數據集</span>針對特定目標微調預訓練模型，使其適應特定任務或領域。</li>
            </ul>
        </div>
        
        <div class="comparison">
            <h5><span class="concept">Fine-tuning 與 RAG 區別 (比較)</span>：</h5>
            <ul>
                <li><strong class="technical-term">Fine-tuning</strong>：需要<span class="highlight">大量計算資源</span>，修改模型本身的權重，適用於需要模型深層理解和生成特定風格內容的場景。</li>
                <li><strong class="technical-term">RAG (檢索增強生成)</strong>：可以<span class="highlight">動態擴充知識，無需重新練習或對整個模型進行重新訓練</span>，使得模型能夠處理更新、更具體的資訊，適用於需要即時訪問外部知識的場景。</li>
                <li><span class="application">實際案例 (RAG)</span>：透過整合資料庫提升回覆準確度，例如從最新的財報和分析報告中檢索資訊，提供更精確的投資建議。</li>
            </ul>
        </div>
        
        <div class="error-analysis">
            <strong class="important">錯題詳解</strong>：<strong>RAG模型在生成回答前會先進行哪一個步驟？</strong>
            <ul>
                <li><strong class="important">正確答案：(C) 檢索相關資料</strong>。</li>
                <li><strong>解釋</strong>：RAG 模型 (Retrieval-Augmented Generation Model, 檢索增強生成模型) 是一種結合了<span class="highlight">檢索</span>和<span class="highlight">生成</span>能力的新型大型語言模型（LLM）。在生成回答之前，它會先去一個外部的、最新的知識庫中「檢索」出最相關的文本片段或文檔，然後再結合這些檢索到的資訊和自身的語言生成能力來構建答案。</li>
                <li><strong class="analogy">白話比喻</strong>：想像 RAG 模型就像一個「學霸助理」。當你問它一個問題時，它不會只憑自己的記憶（訓練數據）來回答。它會先快速跑去圖書館（外部知識庫）查閱最新的資料，找到最相關的幾本書或文章，然後再綜合這些資料和自己的理解來給你一個更精準、更全面的答案。</li>
                <li><strong>其他選項為何不正確</strong>：
                    <ul>
                        <li>(A) 微調語言模型：這不是 RAG 模型在每次生成回答前的<span class="highlight">即時</span>步驟。</li>
                        <li>(B) 資料增強：資料增強是訓練數據預處理的一種技術，與 RAG 模型在推理時的步驟無關。</li>
                        <li>(D) 建立決策樹：這與 RAG 模型的檢索和生成機制無關。</li>
                    </ul>
                </li>
            </ul>
        </div>
        
        <div class="key-concept">
            <ul>
                <li><strong class="technical-term">原生多模態支援</strong>：AI 模型能<span class="highlight">理解並生成文字、影像、語音與影片輸出</span>，代表 AI 模型在不同數據形式之間進行無縫處理的能力。<span class="application">實際案例</span>：OpenAI 的 GPT-4o 具備語音與視覺處理能力。</li>
            </ul>
        </div>

        <h4><span class="technical-term">提示工程 (Prompt Engineering)</span></h4>
        
        <div class="definition">
            <ul>
                <li><strong>目的與運作原理</strong>：透過<span class="highlight">精心設計的輸入指令 (Prompt)</span>，引導生成式 AI 產生更精確、相關和符合預期的輸出。它涉及如何撰寫有效的提示語來最大化 AI 模型的性能。</li>
            </ul>
        </div>
        
        <div class="key-concept">
            <h5><span class="concept">關鍵技巧</span>：</h5>
            <ul>
                <li><strong class="technical-term">系統提示 (System Message)</strong>：在 AI 交互中用於為 AI 提供特定的<span class="highlight">上下文和回應風格</span>，設定其角色或行為準則。</li>
                <li><strong>提供具體上下文資訊</strong>：很重要，有助於 AI 更準確地理解意圖，<span class="highlight">避免產生錯誤答案</span>。</li>
                <li><strong>透過示例提升 AI 回應準確性</strong>：提供範例以進行<span class="highlight">一次性學習 (Few-shot Learning)</span>，讓 AI 在不進行大量重新訓練的情況下，提高對特定任務的回應準確性。</li>
                <li><strong>高效 Prompt 設計進階技巧</strong>：包括 Few-shot Learning、<span class="highlight">Chain-of-Thought 推理</span>（引導模型逐步思考，類似人類推理過程）、<span class="highlight">Layered Prompting</span>（分層次引導模型）。</li>
            </ul>
        </div>
        
        <div class="error-analysis">
            <strong class="important">錯題詳解</strong>：<strong>Few-shot Prompt通常包含什麼？</strong>
            <ul>
                <li><strong class="important">正確答案：(A) 範例輸入與期望輸出</strong>。</li>
                <li><strong>解釋</strong>：Few-shot Prompt 是一種提示工程的技術。當你希望大型語言模型執行一個任務時，你不會只給它任務的指令，而是會在提示中<span class="highlight">包含幾個「少量的」完成該任務的「範例輸入」和對應的「正確輸出」</span>。模型會透過這些範例來理解任務的模式和期望的行為。</li>
                <li><strong class="analogy">白話比喻</strong>：想像你教一個非常聰明的學生如何解決一類新的數學問題。你不是只告訴他「請解這個方程式」，而是會先給他看：「例題一：輸入是 X，正確答案是 Y；例題二：輸入是 A，正確答案是 B」。學生從這幾個例子中，就能快速學會如何解這類型的方程式。</li>
                <li><strong>其他選項為何不正確</strong>：
                    <ul>
                        <li>(B) 模型權重參數：模型權重參數是模型內部學到的數值，屬於模型本身的結構，不包含在提示中。</li>
                        <li>(C) 雜訊擾動資訊：這通常與對抗性攻擊或數據增強有關，不屬於 Few-shot Prompt 的內容。</li>
                        <li>(D) 不包含任何任務內容：錯誤。Few-shot Prompt 不僅包含任務指令，還透過範例包含了任務的具體內容和執行方式。</li>
                    </ul>
                </li>
            </ul>
        </div>
        
        <div class="error-analysis">
            <strong class="important">錯題詳解</strong>：<strong>Prompt Chaining的主要用途為？</strong>
            <ul>
                <li><strong class="important">正確答案：(B) 將多個提示流程串接，達成複雜任務</strong>。</li>
                <li><strong>解釋</strong>：Prompt Chaining 是一種進階的提示工程技巧。它不是只給大型語言模型（LLM）一個單一的提示來完成一個複雜的任務，而是將一個複雜的任務<span class="highlight">分解成多個較小的、易於管理的子任務</span>。然後，為每個子任務設計一個單獨的提示，並<span class="highlight">將前一個提示的輸出作為下一個提示的輸入</span>，形成一個鏈條。</li>
                <li><strong class="analogy">白話比喻</strong>：想像你要讓一個非常聰明但每次只能專心做一件事的助手完成一份複雜的報告。你會這樣做：先讓他完成市場分析，然後根據分析結果做競爭對手研究，再做 SWOT 分析，最後才提出策略建議。這個「一步一步來，把上一步的成果作為下一步的起點」的過程，就是 Prompt Chaining。</li>
                <li><strong>其他選項為何不正確</strong>：
                    <ul>
                        <li>(A) 產出隨機回應：錯誤。Prompt Chaining 的目的恰恰相反，是為了更精準、有邏輯地控制 LLM 的輸出。</li>
                        <li>(C) 壓縮模型參數：模型參數壓縮是模型優化（如量化、剪枝）的技術，與提示工程無關。</li>
                        <li>(D) 改進資料標註：資料標註是數據預處理的一部分。Prompt Chaining 應用於模型推理階段，不直接改進資料標註本身。</li>
                    </ul>
                </li>
            </ul>
        </div>

        <div class="section-divider"></div>

        <div style="text-align: center; margin-top: 40px; padding: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; border-radius: 10px; font-size: 18px; font-weight: 600;">
            📚 AI 應用規劃師 (初級) 考試(科目一)筆記 📚<br>
            <span style="font-size: 14px; font-weight: 400; margin-top: 10px; display: block;">祝您考試順利！🎯</span>
